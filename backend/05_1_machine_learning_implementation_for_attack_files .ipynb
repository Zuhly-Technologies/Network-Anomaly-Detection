{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sqlalchemy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 211\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sqlalchemy'"
     ]
    }
   ],
   "source": [
    "##  \"all_data.csv\" file is required for the operation of the program.\n",
    "##  \"all_data.csv\" file must be located in the same directory as the program.\n",
    "\n",
    "##  the purpose of this program is to apply machine learning algorithms to the dataset and observe the performance of algorithms.\n",
    "##  the algorithms used are:Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP, Nearest Neighbors\n",
    "##  As the program display output data include: file name, machine learning algorithm name, accuracy,Precision, Recall, F1-score,Time\n",
    "##  the program will create a CSV file that prints the results and a folder containing graphics.\n",
    "\n",
    "##  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "##  http://scikit-learn.org\n",
    "\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.metrics import average_precision_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# %matplotlib inline\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import csv\n",
    "# import time\n",
    "# import warnings\n",
    "# import math\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# result=\"./results/results_1.csv\" #a CSV file is named in which the results are saved.\n",
    "# csv_files=os.listdir(\"attacks\")# CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "# path=\".\\\\attacks\\\\\"\n",
    "# repetition=10\n",
    "\n",
    "\n",
    "# def folder(f_name): #this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
    "#     try:\n",
    "#         if not os.path.exists(f_name):\n",
    "#             os.makedirs(f_name)\n",
    "#     except OSError:\n",
    "#         print (\"The folder could not be created!\")\n",
    "\n",
    "# folder_name=\"./results/\"\n",
    "# folder(folder_name)\n",
    "# folder_name=\"./results/result_graph_1/\"\n",
    "# folder(folder_name)\n",
    "\n",
    "\n",
    "# #The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "# ml_list={\n",
    "# \"Naive Bayes\":GaussianNB(),\n",
    "# \"QDA\":QDA(),\n",
    "# \"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "# \"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "# \"AdaBoost\":AdaBoostClassifier(),\n",
    "# \"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "# \"Nearest Neighbors\":KNeighborsClassifier(3)}\n",
    "\n",
    "\n",
    "\n",
    "# # the features to be used for each attack type is defined in a dictionary(features).\n",
    "# # the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "# features={\"Bot\":[\"Bwd Packet Length Mean\",\"Flow IAT Max\",\"Flow Duration\",\"Flow IAT Min\",\"Label\"],\n",
    "# \"DDoS\":[\"Bwd Packet Length Std\",\"Total Backward Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
    "# \"DoS GoldenEye\":[\"Flow IAT Max\",\"Bwd Packet Length Std\",\"Flow IAT Min\",\"Total Backward Packets\",\"Label\"],\n",
    "# \"DoS Hulk\":[\"Bwd Packet Length Std\",\"Fwd Packet Length Std\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Label\"],\n",
    "# \"DoS Slowhttptest\":[\"Flow IAT Mean\",\"Fwd Packet Length Min\",\"Bwd Packet Length Mean\",\"Total Length of Bwd Packets\",\"Label\"],\n",
    "# \"DoS slowloris\":[\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Bwd Packet Length Mean\",\"Total Fwd Packets\",\"Label\"],\n",
    "# \"FTP-Patator\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Std\",\"Fwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Label\"],\n",
    "# \"Heartbleed\":[\"Total Backward Packets\",\"Fwd Packet Length Max\",\"Flow IAT Min\",\"Bwd Packet Length Max\",\"Label\"],\n",
    "# \"Infiltration\":[\"Fwd Packet Length Max\",\"Fwd Packet Length Mean\",\"Flow Duration\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "# \"PortScan\":[\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Fwd IAT Total\",\"Flow Duration\",\"Label\"],\n",
    "# \"SSH-Patator\":[\"Fwd Packet Length Max\",\"Flow Duration\",\"Flow IAT Max\",\"Total Length of Fwd Packets\",\"Label\"],\n",
    "# \"Web Attack\":[\"Bwd Packet Length Std\",\"Total Length of Fwd Packets\",\"Flow Bytes/s\",\"Flow IAT Max\",\"Label\"]}\n",
    "\n",
    "# seconds=time.time()#time stamp for all processing time\n",
    "\n",
    "\n",
    "\n",
    "# with open(result, \"w\", newline=\"\",encoding=\"utf-8\") as f:#a CSV file is created to save the results obtained.\n",
    "#     wrt = csv.writer(f)\n",
    "#     wrt.writerow([\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for j in csv_files: #this loop runs on the list containing the filenames.Operations are repeated for all attack files\n",
    "#     print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))# print output header\n",
    "#     a=[]\n",
    "    \n",
    "#     feature_list=list(features[j[0:-4]])\n",
    "#     df=pd.read_csv(path+j,usecols=feature_list)#read an attack file.\n",
    "#     df=df.fillna(0)\n",
    "#     attack_or_not=[]\n",
    "#     for i in df[\"Label\"]: #it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        \n",
    "#         if i ==\"BENIGN\":\n",
    "#             attack_or_not.append(1)\n",
    "#         else:\n",
    "#             attack_or_not.append(0)           \n",
    "#     df[\"Label\"]=attack_or_not\n",
    "\n",
    "    \n",
    "#     y = df[\"Label\"] #this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "#     del df[\"Label\"]\n",
    "#     feature_list.remove('Label')\n",
    "#     X = df[feature_list]\n",
    "\n",
    "    \n",
    "#     for ii in ml_list: #this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "#         precision=[]\n",
    "#         recall=[]\n",
    "#         f1=[]\n",
    "#         accuracy=[]\n",
    "#         t_time=[]\n",
    "#         for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "#             second=time.time()#time stamp for processing time\n",
    "\n",
    "#             # cross-validation\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y,#  data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train,%20 test). \n",
    "#                 test_size = 0.20, random_state = repetition)#  So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "\n",
    "#             #machine learning algorithm is applied in this section\n",
    "#             clf = ml_list[ii]#choose algorithm from ml_list dictionary                                                                          \n",
    "#             clf.fit(X_train, y_train)\n",
    "#             predict =clf.predict(X_test)\n",
    "        \n",
    "#             #makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "                  \n",
    "#             f_1=f1_score(y_test, predict, average='macro')\n",
    "#             pr=precision_score(y_test, predict, average='macro')\n",
    "#             rc=recall_score(y_test, predict, average='macro')\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             precision.append(float(pr))\n",
    "#             recall.append(float(rc))\n",
    "#             f1.append(float(f_1))\n",
    "#             accuracy.append(clf.score(X_test, y_test))\n",
    "#             t_time.append(float((time.time()-second)) )\n",
    "\n",
    "\n",
    "            \n",
    "#         print ('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4],ii,str(round(np.mean(accuracy),2)),str(round(np.mean(precision),2)), \n",
    "#             str(round(np.mean(recall),2)),str(round(np.mean(f1),2)),str(round(np.mean(t_time),4))))#the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "#         with open(result, \"a\", newline=\"\",encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "#             wrt = csv.writer(f)\n",
    "#             for i in range(0,len(t_time)):\n",
    "#                 wrt.writerow([j[0:-4],ii,accuracy[i],precision[i],recall[i],f1[i],t_time[i]])#file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "#         a.append(f1)\n",
    "\n",
    "\n",
    "#      # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feaure_graph folder.\n",
    "\n",
    "     \n",
    "#     ml=[\"Naive Bayes\",\"QDA\",\"Random Forest\",\"ID3\",\"AdaBoost\",\"MLP\",\"Nearest Neighbors\"]\n",
    "#     temp=0\n",
    "#     fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 6), sharey=True)\n",
    "#     for c in range(2):\n",
    "#         for b in range(4):\n",
    "#             axes[c, b].boxplot(a[temp] )\n",
    "#             axes[c, b].set_title(str(j[0:-4])+\" - \"+str(ml[temp]),fontsize=7)\n",
    "#             axes[c, b].set_ylabel((\"F measure\"))\n",
    "#             temp+=1\n",
    "#             if temp==7:\n",
    "#                 break\n",
    "#         if temp==7:\n",
    "#             break\n",
    "#     plt.savefig(folder_name+j[0:-4]+\".pdf\",bbox_inches='tight', papertype = 'a4', orientation = 'portrait', format = 'pdf')\n",
    "#     plt.show()\n",
    "#     print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "    \n",
    "# print(\"mission accomplished!\")\n",
    "# print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")\n",
    "\n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Database connection\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "host = os.getenv(\"HOST\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "usr = os.getenv(\"USR\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "port = os.getenv(\"PORT\")\n",
    "engine = create_engine(f'postgresql://{usr}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "result = \"./results/results_1.csv\" # a CSV file is named in which the results are saved.\n",
    "csv_files = os.listdir(\"./attacks/\") # CSV files names: #The names of the files in the attacks folder are taken and assigned to a list (csv_files).\n",
    "path = \"./attacks/\"\n",
    "repetition = 10\n",
    "\n",
    "def folder(f_name): # this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print(\"The folder could not be created!\")\n",
    "\n",
    "folder_name = \"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name = \"./results/result_graph_1/\"\n",
    "folder(folder_name)\n",
    "\n",
    "# The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "ml_list = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"QDA\": QDA(),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"ID3\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\"),\n",
    "    # \"AdaBoost\": AdaBoostClassifier(),\n",
    "    # \"MLP\": MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500),\n",
    "    # \"Nearest Neighbors\": KNeighborsClassifier(3)\n",
    "}\n",
    "\n",
    "# the features to be used for each attack type is defined in a dictionary(features).\n",
    "# the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "features = {\n",
    "    \"Bot\": [\"Bwd Packet Length Mean\", \"Flow IAT Max\", \"Flow Duration\", \"Flow IAT Min\", \"Label\"],\n",
    "    \"DDoS\": [\"Bwd Packet Length Std\", \"Total Backward Packets\", \"Fwd IAT Total\", \"Flow Duration\", \"Label\"],\n",
    "    \"DoS GoldenEye\": [\"Flow IAT Max\", \"Bwd Packet Length Std\", \"Flow IAT Min\", \"Total Backward Packets\", \"Label\"],\n",
    "    \"DoS Hulk\": [\"Bwd Packet Length Std\", \"Fwd Packet Length Std\", \"Fwd Packet Length Max\", \"Flow IAT Min\", \"Label\"],\n",
    "    \"DoS Slowhttptest\": [\"Flow IAT Mean\", \"Fwd Packet Length Min\", \"Bwd Packet Length Mean\", \"Total Length of Bwd Packets\", \"Label\"],\n",
    "    \"DoS slowloris\": [\"Flow IAT Mean\", \"Total Length of Bwd Packets\", \"Bwd Packet Length Mean\", \"Total Fwd Packets\", \"Label\"],\n",
    "    \"FTP-Patator\": [\"Fwd Packet Length Max\", \"Fwd Packet Length Std\", \"Fwd Packet Length Mean\", \"Bwd Packet Length Std\", \"Label\"],\n",
    "    \"Heartbleed\": [\"Total Backward Packets\", \"Fwd Packet Length Max\", \"Flow IAT Min\", \"Bwd Packet Length Max\", \"Label\"],\n",
    "    \"Infiltration\": [\"Fwd Packet Length Max\", \"Fwd Packet Length Mean\", \"Flow Duration\", \"Total Length of Fwd Packets\", \"Label\"],\n",
    "    \"PortScan\": [\"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd IAT Total\", \"Flow Duration\", \"Label\"],\n",
    "    \"SSH-Patator\": [\"Fwd Packet Length Max\", \"Flow Duration\", \"Flow IAT Max\", \"Total Length of Fwd Packets\", \"Label\"],\n",
    "    \"Web Attack\": [\"Bwd Packet Length Std\", \"Total Length of Fwd Packets\", \"Flow Bytes/s\", \"Flow IAT Max\", \"Label\"]\n",
    "}\n",
    "\n",
    "seconds = time.time() # time stamp for all processing time\n",
    "\n",
    "with open(result, \"w\", newline=\"\", encoding=\"utf-8\") as f: # a CSV file is created to save the results obtained.\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\"])\n",
    "\n",
    "for j in csv_files: # this loop runs on the list containing the filenames. Operations are repeated for all attack files\n",
    "    print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\")) # print output header\n",
    "    a = []\n",
    "    \n",
    "    feature_list = list(features[j[0:-4]])\n",
    "    df = pd.read_csv(path + j, usecols = feature_list) # read an attack file.\n",
    "    df = df.fillna(0)\n",
    "    attack_or_not = []\n",
    "    for i in df[\"Label\"]: # it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        if i == \"BENIGN\":\n",
    "            attack_or_not.append(1)\n",
    "        else:\n",
    "            attack_or_not.append(0)           \n",
    "    df[\"Label\"] = attack_or_not\n",
    "\n",
    "    y = df[\"Label\"] # this section separates the label and the data into two separate pieces, as Label=y Data=X \n",
    "    del df[\"Label\"]\n",
    "    feature_list.remove('Label')\n",
    "    X = df[feature_list]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for ii in ml_list: # this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "        accuracy = []\n",
    "        t_time = []\n",
    "        for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "            second = time.time() # time stamp for processing time\n",
    "\n",
    "            # cross-validation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, # data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train, 20% test). \n",
    "                test_size = 0.20, random_state = repetition) # So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "            # Check if there are at least 2 classes in y_train and y_test\n",
    "            unique_train = np.unique(y_train)\n",
    "            unique_test = np.unique(y_test)\n",
    "            if len(unique_train) < 2 or len(unique_test) < 2:\n",
    "                print(f\"Skipping {ii} for {j} due to insufficient class diversity. Classes in train: {unique_train}, Classes in test: {unique_test}\")\n",
    "                continue\n",
    "\n",
    "            # Check if any class has only one sample\n",
    "            if any(np.sum(y_train == cls) < 2 for cls in unique_train) or any(np.sum(y_test == cls) < 2 for cls in unique_test):\n",
    "                print(f\"Skipping {ii} for {j} due to insufficient samples in one or more classes.\")\n",
    "                continue\n",
    "\n",
    "            # machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii] # choose algorithm from ml_list dictionary                                                                          \n",
    "            clf.fit(X_train, y_train)\n",
    "            predict = clf.predict(X_test)\n",
    "        \n",
    "            # makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "            f_1 = f1_score(y_test, predict, average='macro')\n",
    "            pr = precision_score(y_test, predict, average='macro')\n",
    "            rc = recall_score(y_test, predict, average='macro')\n",
    "\n",
    "            precision.append(float(pr))\n",
    "            recall.append(float(rc))\n",
    "            f1.append(float(f_1))\n",
    "            accuracy.append(clf.score(X_test, y_test))\n",
    "            t_time.append(float((time.time() - second)))\n",
    "\n",
    "        if precision:  # Check if precision is not empty before proceeding\n",
    "            avg_accuracy = np.mean(accuracy)\n",
    "            avg_precision = np.mean(precision)\n",
    "            avg_recall = np.mean(recall)\n",
    "            avg_f1 = np.mean(f1)\n",
    "            avg_time = np.mean(t_time)\n",
    "\n",
    "            results.append([j[0:-4], ii, avg_accuracy, avg_precision, avg_recall, avg_f1, avg_time])\n",
    "            \n",
    "            print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4], ii, str(round(avg_accuracy, 2)), str(round(avg_precision, 2)), \n",
    "                str(round(avg_recall, 2)), str(round(avg_f1, 2)), str(round(avg_time, 4)))) # the result of the ten repetitions is printed on the screen\n",
    "\n",
    "    if results:\n",
    "        df_results = pd.DataFrame(results, columns=[\"Attack\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\"])\n",
    "        df_results = df_results.round(3)  # Round all values to 3 decimal places\n",
    "        df_results.to_sql(j[0:-4], engine, if_exists='replace', index=False)\n",
    "\n",
    "        with open(result, \"a\", newline=\"\", encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "            wrt = csv.writer(f)\n",
    "            wrt.writerows(df_results.values.tolist())  # Convert DataFrame to list of lists before writing to CSV\n",
    "\n",
    "    # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feature_graph folder.\n",
    "    # ml = [\"Naive Bayes\", \"QDA\", \"Random Forest\", \"ID3\", \"AdaBoost\", \"MLP\", \"Nearest Neighbors\"]\n",
    "    ml = [\"Naive Bayes\", \"QDA\", \"Random Forest\", \"ID3\"]\n",
    "    temp = 0\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 6), sharey=True)\n",
    "    for c in range(2):\n",
    "        for b in range(4):\n",
    "            if temp >= len(a): # check if temp is within bounds\n",
    "                break\n",
    "            axes[c, b].boxplot(a[temp])\n",
    "            axes[c, b].set_title(str(j[0:-4]) + \" - \" + str(ml[temp]), fontsize=7)\n",
    "            axes[c, b].set_ylabel((\"F measure\"))\n",
    "            temp += 1\n",
    "            if temp == 4:\n",
    "                break\n",
    "        if temp == 4:\n",
    "            break\n",
    "    plt.savefig(folder_name + j[0:-4] + \".pdf\", bbox_inches='tight', format = 'pdf')\n",
    "    plt.show()\n",
    "    print(\"\\n------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \", time.time()- seconds ,\"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
