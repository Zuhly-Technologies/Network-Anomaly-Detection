{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 167\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "#  \"all_data.csv\" file is required for the operation of the program.\n",
    "#  \"all_data.csv\" file must be located in the same directory as the program.\n",
    "\n",
    "#  the purpose of this program is to apply machine learning algorithms to the dataset and observe the performance of algorithms.\n",
    "#  the algorithms used are:Naive Bayes, QDA, Random Forest, ID3, AdaBoost, MLP, Nearest Neighbors\n",
    "#  As the program display output data include: file name, machine learning algorithm name, accuracy,Precision, Recall, F1-score,Time\n",
    "#  the program will create a CSV file that prints the results and a folder containing graphics.\n",
    "\n",
    "#  the some codes parts used for calculation and graphing are taken from the following site.\n",
    "#  http://scikit-learn.org\n",
    "\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.metrics import average_precision_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import csv\n",
    "# import time\n",
    "# import warnings\n",
    "# import math\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# result = \"./results/results_2.csv\" # a CSV file is named in which the results are saved.\n",
    "# csv_files = [\"all_data.csv\"] # CSV files names: #The names of the dataset files (csv_files).\n",
    "# path = \"\"\n",
    "# repetition = 10\n",
    "\n",
    "# def folder(f_name): # this function creates a folder named \"results\" and \"result_graph_1\" in the program directory.\n",
    "#     try:\n",
    "#         if not os.path.exists(f_name):\n",
    "#             os.makedirs(f_name)\n",
    "#     except OSError:\n",
    "#         print(\"The folder could not be created!\")\n",
    "\n",
    "# folder_name = \"./results/\"\n",
    "# folder(folder_name)\n",
    "# folder_name = \"./results/result_graph_2/\"\n",
    "# folder(folder_name)\n",
    "\n",
    "# # The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "# # ml_list = {\n",
    "# #     \"Naive Bayes\": GaussianNB(),\n",
    "# #     \"QDA\": QDA(),\n",
    "# #     \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "# #     \"ID3\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\"),\n",
    "# #     \"AdaBoost\": AdaBoostClassifier(),\n",
    "# #     \"MLP\": MLPClassifier(hidden_layer_sizes=(13,13,13), max_iter=500),\n",
    "# #     \"Nearest Neighbors\": KNeighborsClassifier(3)\n",
    "# # }\n",
    "\n",
    "# ml_list = {\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     \"QDA\": QDA(),\n",
    "#     \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     \"ID3\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\"),\n",
    "#     # \"AdaBoost\": AdaBoostClassifier(),\n",
    "#     # \"MLP\": MLPClassifier(hidden_layer_sizes=(13,13,13), max_iter=500),\n",
    "#     # \"Nearest Neighbors\": KNeighborsClassifier(3)\n",
    "# }\n",
    "\n",
    "# # the features to be used for each attack type is defined in a dictionary(features).\n",
    "# # the first 4 of the features created by the file \"04_1_feature_selection_for_attack_files.py\" are used here.\n",
    "# features = {\"all_data\": [\"Bwd Packet Length Max\",\"Bwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Flow Bytes/s\",\n",
    "# \"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Flow IAT Min\",\"Flow IAT Std\",\"Fwd IAT Total\",\"Fwd Packet Length Max\",\n",
    "# \"Fwd Packet Length Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Total Backward Packets\",\"Total Fwd Packets\",\n",
    "# \"Total Length of Bwd Packets\",\"Total Length of Fwd Packets\",\"Label\"]}\n",
    "\n",
    "# seconds = time.time() # time stamp for all processing time\n",
    "\n",
    "# with open(result, \"w\", newline=\"\", encoding=\"utf-8\") as f: # a CSV file is created to save the results obtained.\n",
    "#     wrt = csv.writer(f)\n",
    "#     wrt.writerow([\"File\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\"])\n",
    "\n",
    "# for j in csv_files: # this loop runs on the list containing the filenames. Operations are repeated for all attack files\n",
    "#     print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\")) # print output header   \n",
    "#     feature_list = list(features[j[0:-4]])\n",
    "#     df = pd.read_csv(path + j, usecols = feature_list) # read an attack file.\n",
    "#     df = df.fillna(0)\n",
    "#     attack_or_not = []\n",
    "#     for i in df[\"Label\"]: # it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "#         if i == \"BENIGN\":\n",
    "#             attack_or_not.append(1)\n",
    "#         else:\n",
    "#             attack_or_not.append(0)           \n",
    "#     df[\"Label\"] = attack_or_not\n",
    "\n",
    "#     y = df[\"Label\"] # this section separates the label and the data into two separate pieces, as Label = y, Data = X \n",
    "#     del df[\"Label\"]\n",
    "#     feature_list.remove('Label')\n",
    "#     X = df[feature_list]\n",
    "\n",
    "#     for ii in ml_list: # this loop runs on the list containing the machine learning algorithm names. Operations are repeated for all the 7 algorithm\n",
    "#         precision = []\n",
    "#         recall = []\n",
    "#         f1 = []\n",
    "#         accuracy = []\n",
    "#         t_time = []\n",
    "#         for i in range(repetition): # This loop allows cross-validation and machine learning algorithm to be repeated 10 times\n",
    "#             second = time.time() # time stamp for processing time\n",
    "\n",
    "#             # cross-validation\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, # data (X) and labels (y) are divided into 2 parts to be sent to the machine learning algorithm (80% train, 20% test). \n",
    "#                 test_size = 0.20, random_state = repetition) # So, in total there are 4 tracks: training data(X_train), training tag (y_train), test data(X_test) and test tag(y_test).\n",
    "\n",
    "#             # machine learning algorithm is applied in this section\n",
    "#             clf = ml_list[ii] # choose algorithm from ml_list dictionary                                                                          \n",
    "#             clf.fit(X_train, y_train)\n",
    "#             predict = clf.predict(X_test)\n",
    "        \n",
    "#             # makes \"classification report\" and assigns the precision, f-measure, and recall values.s.    \n",
    "#             f_1 = f1_score(y_test, predict, average='macro')\n",
    "#             pr = precision_score(y_test, predict, average='macro')\n",
    "#             rc = recall_score(y_test, predict, average='macro')\n",
    "            \n",
    "#             precision.append(float(pr))\n",
    "#             recall.append(float(rc))\n",
    "#             f1.append(float(f_1))\n",
    "#             accuracy.append(clf.score(X_test, y_test))\n",
    "#             t_time.append(float((time.time() - second)))\n",
    "\n",
    "#         print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4], ii, str(round(np.mean(accuracy), 2)), str(round(np.mean(precision), 2)), \n",
    "#             str(round(np.mean(recall), 2)), str(round(np.mean(f1), 2)), str(round(np.mean(t_time), 4)))) # the result of the ten repetitions is printed on the screen.\n",
    "\n",
    "#         with open(result, \"a\", newline=\"\", encoding=\"utf-8\") as f: # all the values found are saved in the opened file.\n",
    "#             wrt = csv.writer(f)\n",
    "#             for i in range(0, len(t_time)):\n",
    "#                 wrt.writerow([j[0:-4], ii, accuracy[i], precision[i], recall[i], f1[i], t_time[i]]) # file name, algorithm name, precision, recall and f-measure are writed in CSV file\n",
    "   \n",
    "#         # In this section, Box graphics are created for the results of machine learning algorithms and saved in the feature_graph folder.\n",
    "#         plt.boxplot(f1)\n",
    "#         plt.title(\"All Dataset - \" + str(ii))\n",
    "#         plt.ylabel('F-measure')\n",
    "#         plt.savefig(folder_name + j[0:-4] + str(ii) + \".pdf\", bbox_inches='tight', format='pdf')\n",
    "#         plt.show() # you can remove the # sign if you want to see the graphics simultaneously\n",
    "\n",
    "# print(\"mission accomplished!\")\n",
    "# print(\"Total operation time: = \", time.time() - seconds, \"seconds\")\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Database connection\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "host = os.getenv(\"HOST\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "usr = os.getenv(\"USR\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "port = os.getenv(\"PORT\")\n",
    "engine = create_engine(f'postgresql://{usr}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "result = \"./results/results_2.csv\"\n",
    "csv_files = [\"all_data.csv\"]\n",
    "path = \"\"\n",
    "repetition = 10\n",
    "\n",
    "def folder(f_name):\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print(\"The folder could not be created!\")\n",
    "\n",
    "folder_name = \"./results/\"\n",
    "folder(folder_name)\n",
    "folder_name = \"./results/result_graph_2/\"\n",
    "folder(folder_name)\n",
    "\n",
    "ml_list = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"QDA\": QDA(),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"ID3\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\"),\n",
    "    # \"AdaBoost\": AdaBoostClassifier(),\n",
    "    # \"MLP\": MLPClassifier(hidden_layer_sizes=(13,13,13), max_iter=500),\n",
    "    # \"Nearest Neighbors\": KNeighborsClassifier(3)\n",
    "}\n",
    "\n",
    "features = {\"all_data\": [\"Bwd Packet Length Max\",\"Bwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Flow Bytes/s\",\n",
    "\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Flow IAT Min\",\"Flow IAT Std\",\"Fwd IAT Total\",\"Fwd Packet Length Max\",\n",
    "\"Fwd Packet Length Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Total Backward Packets\",\"Total Fwd Packets\",\n",
    "\"Total Length of Bwd Packets\",\"Total Length of Fwd Packets\",\"Label\"]}\n",
    "\n",
    "seconds = time.time()\n",
    "\n",
    "with open(result, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    wrt = csv.writer(f)\n",
    "    wrt.writerow([\"File\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\"])\n",
    "\n",
    "def process_file(j):\n",
    "    print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (\"File\",\"ML algorithm\",\"accuracy\",\"Precision\", \"Recall\" , \"F1-score\",\"Time\"))\n",
    "    feature_list = list(features[j[0:-4]])\n",
    "    \n",
    "    # Dask\n",
    "    df = dd.read_csv(path + j, usecols=feature_list).fillna(0).compute()\n",
    "    \n",
    "    # Convert labels to binary values for machine learning\n",
    "    attack_or_not = df[\"Label\"].apply(lambda x: 1 if x == \"BENIGN\" else 0)\n",
    "    df[\"Label\"] = attack_or_not\n",
    "    y = df[\"Label\"]\n",
    "    X = df.drop(columns=[\"Label\"])\n",
    "\n",
    "    results = []\n",
    "    for ii in ml_list:\n",
    "        def run_model(i):\n",
    "            second = time.time()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=repetition)\n",
    "            clf = ml_list[ii]\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict = clf.predict(X_test)\n",
    "            f_1 = f1_score(y_test, predict, average='macro')\n",
    "            pr = precision_score(y_test, predict, average='macro')\n",
    "            rc = recall_score(y_test, predict, average='macro')\n",
    "            return clf.score(X_test, y_test), pr, rc, f_1, time.time() - second\n",
    "\n",
    "        # Limit the number of parallel jobs to manage memory usage\n",
    "        scores = Parallel(n_jobs=4)(delayed(run_model)(i) for i in range(repetition))\n",
    "        accuracy, precision, recall, f1, t_time = zip(*scores)\n",
    "\n",
    "        avg_accuracy = np.mean(accuracy)\n",
    "        avg_precision = np.mean(precision)\n",
    "        avg_recall = np.mean(recall)\n",
    "        avg_f1 = np.mean(f1)\n",
    "        avg_time = np.mean(t_time)\n",
    "\n",
    "        results.append([j[0:-4], ii, round(avg_accuracy, 3), round(avg_precision, 3), round(avg_recall, 3), round(avg_f1, 3), round(avg_time, 3)])\n",
    "\n",
    "        print('%-17s %-17s  %-15s %-15s %-15s %-15s %-15s' % (j[0:-4], ii, round(avg_accuracy, 3), round(avg_precision, 3), \n",
    "            round(avg_recall, 3), round(avg_f1, 3), round(avg_time, 3)))\n",
    "\n",
    "    if results:\n",
    "        df_results = pd.DataFrame(results, columns=[\"Attack\", \"ML algorithm\", \"accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time\"])\n",
    "        df_results.to_sql(\"all_data\", engine, if_exists='replace', index=False)\n",
    "\n",
    "        with open(result, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            wrt = csv.writer(f)\n",
    "            wrt.writerows(results)\n",
    "\n",
    "        # Generate and save boxplots\n",
    "        for algo in ml_list.keys():\n",
    "            f1_scores = [result[5] for result in results if result[1] == algo]\n",
    "            if f1_scores:\n",
    "                plt.boxplot(f1_scores)\n",
    "                plt.title(\"All Dataset - \" + str(algo))\n",
    "                plt.ylabel('F-measure')\n",
    "                plt.savefig(folder_name + \"all_data_\" + str(algo) + \".pdf\", bbox_inches='tight', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "for j in csv_files:\n",
    "    process_file(j)\n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \", time.time() - seconds, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
